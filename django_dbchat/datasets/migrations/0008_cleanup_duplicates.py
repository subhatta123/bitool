# Generated by Django migration for cleaning up duplicate data sources

from django.db import migrations
from collections import defaultdict


def cleanup_duplicates(apps, schema_editor):
    """Clean up duplicate data sources before applying unique constraint"""
    DataSource = apps.get_model('datasets', 'DataSource')
    
    # Group by (created_by, name) and keep the most recent one
    grouped_sources = defaultdict(list)
    
    # Get all non-deleted sources
    all_sources = DataSource.objects.filter(is_deleted=False).order_by('created_at')
    
    for source in all_sources:
        key = (source.created_by_id, source.name)
        grouped_sources[key].append(source)
    
    # Process duplicates
    for (user_id, name), sources in grouped_sources.items():
        if len(sources) > 1:
            # Sort by created_at descending to get most recent first
            sources_sorted = sorted(sources, key=lambda x: x.created_at, reverse=True)
            
            # Keep the most recent one, soft delete the rest
            to_keep = sources_sorted[0]
            to_delete = sources_sorted[1:]
            
            for source in to_delete:
                # Soft delete the duplicate
                source.deleted_at = source.created_at  # Use created_at as deleted_at
                source.is_deleted = True
                source.status = 'inactive'
                source.save()


def reverse_cleanup(apps, schema_editor):
    """Reverse the cleanup - restore soft deleted sources"""
    DataSource = apps.get_model('datasets', 'DataSource')
    DataSource.objects.filter(is_deleted=True).update(
        deleted_at=None,
        is_deleted=False,
        status='active'
    )


class Migration(migrations.Migration):

    dependencies = [
        ('datasets', '0007_add_datasource_table_name'),
    ]

    operations = [
        # Clean up duplicates first
        migrations.RunPython(cleanup_duplicates, reverse_cleanup),
    ] 